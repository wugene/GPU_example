{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pycuda import driver, compiler, gpuarray, tools\n",
    "\n",
    "# -- initialize the device\n",
    "import pycuda.autoinit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kernel_code_template = \"\"\"\n",
    "__global__ void MatrixMulKernel(float *a, float *b, float *c)\n",
    "{\n",
    "    // 2D Thread ID (assuming that only *one* block will be executed)\n",
    "    int tx = threadIdx.x;\n",
    "    int ty = threadIdx.y;\n",
    "\n",
    "    // sum is used to store the element of the matrix\n",
    "    // that is computed by the thread\n",
    "    float sum = 0;\n",
    "\n",
    "    // Each thread loads one row of M and one column of N, \n",
    "    //   to produce one element of P.\n",
    "    for (int k = 0; k < %(MATRIX_SIZE)s; ++k) {\n",
    "        float Aelement = a[ty * %(MATRIX_SIZE)s + k];\n",
    "        float Belement = b[k * %(MATRIX_SIZE)s + tx];\n",
    "        sum += Aelement * Belement;\n",
    "    }\n",
    "\n",
    "    // Write the matrix to device memory;\n",
    "    // each thread writes one element\n",
    "    c[ty * %(MATRIX_SIZE)s + tx] = sum;\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MATRIX_SIZE = 10\n",
    "\n",
    "kernel_code = kernel_code_template % {\n",
    "    'MATRIX_SIZE': MATRIX_SIZE \n",
    "    }\n",
    "\n",
    "# compile the kernel code \n",
    "mod = compiler.SourceModule(kernel_code)\n",
    "\n",
    "# get the kernel function from the compiled module\n",
    "matrixmul = mod.get_function(\"MatrixMulKernel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a_cpu = np.random.randn(MATRIX_SIZE, MATRIX_SIZE).astype(np.float32)\n",
    "b_cpu = np.random.randn(MATRIX_SIZE, MATRIX_SIZE).astype(np.float32)\n",
    "\n",
    "# transfer host (CPU) memory to device (GPU) memory \n",
    "a_gpu = gpuarray.to_gpu(a_cpu) \n",
    "b_gpu = gpuarray.to_gpu(b_cpu)\n",
    "\n",
    "# create empty gpu array for the result (C = A * B)\n",
    "c_gpu = gpuarray.empty((MATRIX_SIZE, MATRIX_SIZE), np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "matrixmul( a_gpu, b_gpu, c_gpu, block = (MATRIX_SIZE, MATRIX_SIZE, 1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-3.4771717   5.482945   -6.292933    4.405063    0.51688236 -3.7065926\n",
      "   1.4674895  -2.6236298   0.5188382   2.271932  ]\n",
      " [-1.8849337   2.7866294   1.4785069  -2.1530461   4.509437   -0.05617753\n",
      "   3.543174   -0.3682125   2.4228332   5.6167655 ]\n",
      " [-0.24747853  1.5168964  -2.2270796   0.13722806  1.0699996  -2.634846\n",
      "   2.7079709  -1.625223   -2.9609628   0.20578751]\n",
      " [ 0.6587145   0.2736324   1.727121   -3.2834382   2.3084679   0.44580218\n",
      "   4.0302997  -1.6936392   3.9337013   3.5753314 ]\n",
      " [-3.6179368  -0.05588313 -0.3640145   2.540673   -3.2270606   0.6209002\n",
      "  -0.7559828  -1.3442806   0.06099317 -1.5197484 ]\n",
      " [-5.6789513   4.888655    1.2472756   0.30557597 -1.7830266  -0.19065507\n",
      "   3.510964   -4.01609    -1.1655627   1.5731109 ]\n",
      " [ 1.0808862   3.7633176  -2.8094559   1.7364875  -3.7730677  -0.26596048\n",
      "  -3.2028282   0.13750798 -3.9100955  -2.3720872 ]\n",
      " [ 4.036247   -5.00309     2.2084363   0.47176293 -4.434005   -1.0028977\n",
      "  -5.2980075   3.7076604  -3.0437567  -5.400503  ]\n",
      " [ 4.707275   -0.538864    1.134631   -2.2661781  -4.000026   -4.4882965\n",
      "  -1.1282977   1.557384   -4.8788238  -2.190154  ]\n",
      " [-5.4365277   3.1843925  -0.27885816  0.93483764  1.4170785   1.81437\n",
      "   1.853431   -0.16706073  0.37167796  2.6031117 ]]\n"
     ]
    }
   ],
   "source": [
    "print(c_gpu.get())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96.1 µs ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "# call the kernel on the card\n",
    "%timeit -n 1 -r 1 matrixmul( a_gpu, b_gpu, c_gpu, block = (MATRIX_SIZE, MATRIX_SIZE, 1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_cpu = np.random.randn(4000, 4000).astype(np.float32)\n",
    "x_gpu = gpuarray.to_gpu(x_cpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000, 4000)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_gpu.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_gpu_2 = x_gpu * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(2., dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpuarray.max(x_gpu_2 / x_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(2., dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpuarray.min(x_gpu_2 / x_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199 ms ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 1 -r 1 x_sum_gpu = gpuarray.sum(x_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55 ms ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 1 -r 1 x_sum_gpu2 = x_gpu.get().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w_cpu = np.random.randn(1000, 1000).astype(np.float32)\n",
    "v_cpu = np.random.randn(1000, 1000).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w_gpu = gpuarray.to_gpu(w_cpu)\n",
    "v_gpu = gpuarray.to_gpu(v_cpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
